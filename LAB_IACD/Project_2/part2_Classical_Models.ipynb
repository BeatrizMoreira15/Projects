{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos Clássicos** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibliotecas Necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ler e separar os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Data_noNorm.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Garantir que a coluna 'Date' está no formato correto e sem o fuso horário\n",
    "data['Date'] = pd.to_datetime(data['Date'])  # Converter para datetime\n",
    "data.set_index('Date', inplace=True)  # Definir 'Date' como índice\n",
    "\n",
    "# Separar os conjuntos de treino, validação e teste\n",
    "train_data = data.loc[:'2022-12-31']\n",
    "val_data = data.loc['2023-01-01':'2023-12-31']\n",
    "test_data = data.loc['2024-01-01':'2024-01-31']\n",
    "\n",
    "# Separar features (X) e target (y)\n",
    "X_train = train_data.drop(columns=['Future_Return'])\n",
    "y_train = train_data['Future_Return']\n",
    "\n",
    "X_val = val_data.drop(columns=['Future_Return'])\n",
    "y_val = val_data['Future_Return']\n",
    "\n",
    "X_test = test_data.drop(columns=['Future_Return'])\n",
    "y_test = test_data['Future_Return']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escolha das melhores features, com recurso ao modelo LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optamos por escolher o **LightGBM**, por ser um modelo com elevada capacidade em lidar com um grande volume de dados, com padrões complexos.\\\n",
    "Além disso, apresenta uma boa eficiência computacional, sem introduzir ruído.\n",
    "\n",
    ">Referência: *Ke, Guolin, et al. \"LightGBM: A highly efficient gradient boosting decision tree.\" Advances in Neural Information Processing Systems. 2017*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=3500, \n",
    "    max_depth=10, \n",
    "    learning_rate=0.001,\n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = lgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot das melhores features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X_train.columns, feature_importances)\n",
    "plt.ylabel('Índice das Features')\n",
    "plt.xlabel('Importância')\n",
    "plt.title('Importância das Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolhemos as features com importancia superior à **mediana** das *feature_importances*, uma vez que a mediana não é influenciada por valores extremamente altos ou baixos, ao contrário da média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X_train.columns[feature_importances > np.median(feature_importances)]\n",
    "print(f\"Features selecionadas: {list(selected_features)}\")\n",
    "\n",
    "# Reduzir os datasets às features selecionadas\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Normalização dos dados usando o Min-Max**\n",
    "\n",
    "Ideal para colunas com valores que possuem limites conhecidos ou métricas específicas que variam dentro de uma faixa pré-definida.\\\n",
    "Neste caso, podemos aplicar o **Min-Max** a indicadores técnicos como *RSI* e *Momentum*.\n",
    "\n",
    "**2. StandardScaler**\n",
    "\n",
    "Ideal para variáveis cujas escalas não são limitadas, especialmente aquelas diretamente relacionadas a preços, volumes e volatilidades.\\\n",
    "Assim, podemos aplicar o **StandardScaler** às seguintes features:\n",
    "\n",
    "- Preços e volumes:\n",
    "    - *Close*;\n",
    "    - *Volume*;\n",
    "    - *Daily_Return*.\n",
    "\n",
    "- Indicadores de risco e volatilidade:\n",
    "    - *Rolling_Volatility*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Este documento fornece suporte empírico para a utilização da normalização do Z-score e do Min-Max Scaling em tarefas de previsão de ações \\\n",
    "Referência:\n",
    "*\"Forecasting Daily Stock Movement Using a Hybrid Normalization Based Intersection Feature Selection and ANN\" by Kumari Binita and Swarnkar Tripti (2023)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "cols_to_normalize_minmax = [col for col in selected_features if col in ['RSI', 'Momentum_10']]\n",
    "cols_to_normalize_standard = [col for col in selected_features if col in ['Close', 'Volume', 'Daily_Return', 'Rolling_Volatility']]\n",
    "\n",
    "# Criar cópias para evitar modificar os dados originais\n",
    "X_train_normalized = X_train_selected.copy()\n",
    "X_val_normalized = X_val_selected.copy()\n",
    "X_test_normalized = X_test_selected.copy()\n",
    "\n",
    "# Aplicar normalização Min-Max nas colunas definidas\n",
    "X_train_normalized[cols_to_normalize_minmax] = min_max_scaler.fit_transform(X_train_selected[cols_to_normalize_minmax])\n",
    "X_val_normalized[cols_to_normalize_minmax] = min_max_scaler.transform(X_val_selected[cols_to_normalize_minmax])\n",
    "X_test_normalized[cols_to_normalize_minmax] = min_max_scaler.transform(X_test_selected[cols_to_normalize_minmax])\n",
    "\n",
    "# Aplicar normalização StandardScaler nas colunas definidas\n",
    "X_train_normalized[cols_to_normalize_standard] = standard_scaler.fit_transform(X_train_selected[cols_to_normalize_standard])\n",
    "X_val_normalized[cols_to_normalize_standard] = standard_scaler.transform(X_val_selected[cols_to_normalize_standard])\n",
    "X_test_normalized[cols_to_normalize_standard] = standard_scaler.transform(X_test_selected[cols_to_normalize_standard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função para calcular R^2, a partir do coeficiente de pearson**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y_real, y_pred):   \n",
    "    # Calcular as médias\n",
    "    mean_y_real = np.mean(y_real)\n",
    "    mean_y_pred = np.mean(y_pred)\n",
    "\n",
    "    # Numerador: Covariância entre y_real e y_pred\n",
    "    covariance = np.sum((y_real - mean_y_real) * (y_pred - mean_y_pred))\n",
    "\n",
    "    # Denominador: Produto dos desvios padrão de y_real e y_pred\n",
    "    std_y_real = np.sqrt(np.sum((y_real - mean_y_real) ** 2))\n",
    "    std_y_pred = np.sqrt(np.sum((y_pred - mean_y_pred) ** 2))\n",
    "\n",
    "    # Coeficiente de correlação de Pearson (r)\n",
    "    pearson_r = covariance / (std_y_real * std_y_pred)\n",
    "\n",
    "    r2_pearson = pearson_r ** 2\n",
    "    return r2_pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos implementar 3 modelos diferentes de Machine Learning, o **AdaBoost**, **XGBoost** e o **LoghtGBM**, para prever os retornos diários de cada ação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AdaBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, recorremos ao **Adaboost** por ser um modelo robusto em lidar com dados de alta dimensionalidade, além de ter uma boa capacidade para capturar padrões não lineares e revelar um bom desempenho em estudos de contexto financeiro.\n",
    "\n",
    "Acresce o facto deste modelo possuir ferramentas para reduzir o impacto do ruídos dos dados, uma vez que ele é capaz de se ajustar e focar-se em padrões consistentes, melhorando assim a sua generalização.\n",
    "\n",
    ">Referências:\\\n",
    "https://www.sciencedirect.com/science/article/pii/S1062940824001669 \\\n",
    "https://www.kaggle.com/code/meuge672/predicting-price-with-adaboost-and-regression#AdaBoost-Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o AdaBoost\n",
    "adaboost_model = AdaBoostRegressor(n_estimators=20, learning_rate=0.001, loss='exponential', random_state=42)\n",
    "\n",
    "# Treinar o modelo com o conjunto de treino\n",
    "adaboost_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Avaliar o modelo no conjunto de validação\n",
    "y_val_pred = adaboost_model.predict(X_val_normalized)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_r2 = r2(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validação - MAE: {val_mae:.5f}\")\n",
    "print(f\"Validação - MSE: {val_mse:.5f}\")\n",
    "print(f\"Validação - RMSE: {val_rmse:.5f}\")\n",
    "print(f\"Validação - R²: {val_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar no conjunto combinado (treino + validação)\n",
    "X_train_val_selected = pd.concat([X_train_normalized, X_val_normalized])\n",
    "y_train_val = pd.concat([y_train, y_val])\n",
    "adaboost_model.fit(X_train_val_selected, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o conjunto de teste\n",
    "y_test_pred = adaboost_model.predict(X_test_normalized)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Teste - MAE: {test_mae:.5f}\")\n",
    "print(f\"Teste - MSE: {test_mse:.5f}\")\n",
    "print(f\"Teste - RMSE: {test_rmse:.5f}\")\n",
    "print(f\"Teste - R²: {test_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots dos Valores Reais e dos Valores Previstos por Empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o DataFrame com os valores reais e previstos\n",
    "y_test_df = pd.DataFrame(y_test.values, columns=['Real_Return'], index=y_test.index)\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred, columns=['Predicted_Return'], index=y_test.index)\n",
    "\n",
    "# Concatenar os valores reais, previstos e os Tickers \n",
    "df_test = pd.concat([y_test_df, y_test_pred_df], axis=1)\n",
    "df_test['Ticker'] = X_test['Ticker']\n",
    "\n",
    "# Gráficos por empresa\n",
    "tickers = df_test['Ticker'].unique()\n",
    "n_col = 5  # Número de gráficos por linha \n",
    "n_row = int(np.ceil(len(tickers) / n_col))  # Número de linhas necessárias\n",
    "\n",
    "print(\"Linha azul --- Valores Reais\")\n",
    "print(\"Linha laranja --- Valores Previstos\")\n",
    "\n",
    "# Criar os subgráficos\n",
    "fig, axes = plt.subplots(n_row, n_col, figsize=(18, 3 * n_row))  \n",
    "axes = axes.flatten()  \n",
    "\n",
    "# Iterar sobre os tickers e plotar os gráficos\n",
    "for i, ticker in enumerate(tickers):\n",
    "    # Filtrar os dados para o Ticker específico\n",
    "    ticker_data = df_test[df_test['Ticker'] == ticker]\n",
    "    \n",
    "    # Plotar os valores reais e previstos ao longo do tempo\n",
    "    ax = axes[i]    \n",
    "    ax.plot(ticker_data.index, ticker_data['Real_Return'], label='Valores Reais', color='blue')\n",
    "    ax.plot(ticker_data.index, ticker_data['Predicted_Return'], label='Previsões', color='orange', linestyle='dashed')\n",
    "    ax.set_title(f'Previsão de Retornos para {ticker}', fontsize=6)  \n",
    "    ax.set_xlabel('Data', fontsize=6) \n",
    "    ax.set_ylabel('Retorno Futuro', fontsize=6) \n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=6)  \n",
    "    ax.tick_params(axis='y', labelsize=6)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5, right=0.85)  \n",
    "plt.tight_layout(pad=3.0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar o csv com os valores reais e previstos\n",
    "df_test.to_csv(\"predicted_vs_real_returns_adaboost.csv\", index=True)\n",
    "print(\"DataFrame salvo como 'predicted_vs_real_returns_adaboost.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, decidimos utilizar o **XGBoost** por ser um modelo eficiente em classificações e por apresentar um desempenho positivo com grandes volumes de dados.\n",
    "\n",
    ">Referência: https://www.researchgate.net/publication/379076543_Predicting_the_SP_500_stock_market_with_machine_learning_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=900,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.001,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Avaliar o conjunto de validação\n",
    "y_val_pred = xgb_model.predict(X_val_normalized)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_r2 = r2(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validação - MAE: {val_mae:.5f}\")\n",
    "print(f\"Validação - MSE: {val_mse:.5f}\")\n",
    "print(f\"Validação - RMSE: {val_rmse:.5f}\")\n",
    "print(f\"Validação - R²: {val_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_val_selected, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o conjunto de teste\n",
    "y_test_pred = xgb_model.predict(X_test_normalized)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "val_r2 = r2(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Teste - MAE: {test_mae:.5f}\")\n",
    "print(f\"Teste - MSE: {test_mse:.5f}\")\n",
    "print(f\"Teste - RMSE: {test_rmse:.5f}\")\n",
    "print(f\"Teste - R²: {val_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots dos Valores Reais e dos Valores Previstos por Empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o DataFrame com os valores reais e previstos\n",
    "y_test_df = pd.DataFrame(y_test.values, columns=['Real_Return'], index=y_test.index)\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred, columns=['Predicted_Return'], index=y_test.index)\n",
    "df_test = pd.concat([y_test_df, y_test_pred_df], axis=1)\n",
    "df_test['Ticker'] = X_test['Ticker']\n",
    "\n",
    "# Gráficos por empresa\n",
    "tickers = df_test['Ticker'].unique()\n",
    "n_col = 5\n",
    "n_row = int(np.ceil(len(tickers) / n_col))\n",
    "\n",
    "# Criar os subgráficos\n",
    "fig, axes = plt.subplots(n_row, n_col, figsize=(18, 3 * n_row))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ticker_data = df_test[df_test['Ticker'] == ticker]\n",
    "    ax = axes[i]\n",
    "    ax.plot(ticker_data.index, ticker_data['Real_Return'], label='Valores Reais', color='blue')\n",
    "    ax.plot(ticker_data.index, ticker_data['Predicted_Return'], label='Previsões', color='orange', linestyle='dashed')\n",
    "    ax.set_title(f'Previsão de Retornos para {ticker}', fontsize=6)\n",
    "    ax.set_xlabel('Data', fontsize=6)\n",
    "    ax.set_ylabel('Retorno Futuro', fontsize=6)\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=6)\n",
    "    ax.tick_params(axis='y', labelsize=6)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5, right=0.85)\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar o csv com os valores reais e previstos\n",
    "df_test.to_csv(\"predicted_vs_real_returns_xgboost.csv\", index=True)\n",
    "print(\"DataFrame salvo como 'predicted_vs_real_returns_xgboost.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, optamos por usar também o **LightGBM** pela sua eficiência computacional e pela capacidade de lidar com dados complexos e de alta dimensionalidade.\n",
    "\n",
    ">Referência: \\\n",
    "https://www.researchgate.net/publication/347420761_Predicting_the_SP500_Index_Trend_Based_on_GBDT_and_LightGBM_Methods \\\n",
    "https://www.sciencedirect.com/science/article/pii/S1877050922020130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=900,          \n",
    "    learning_rate=0.001,       \n",
    "    random_state=42,            \n",
    "    n_jobs=-1             \n",
    ")\n",
    "\n",
    "# Treinar o modelo com o conjunto de treino\n",
    "model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Avaliar o modelo no conjunto de validação\n",
    "y_val_pred = model.predict(X_val_normalized)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_r2 = r2(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validação - MAE: {val_mae:.5f}\")\n",
    "print(f\"Validação - MSE: {val_mse:.5f}\")\n",
    "print(f\"Validação - RMSE: {val_rmse:.5f}\")\n",
    "print(f\"Validação - R²: {val_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_val_selected, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o conjunto de teste\n",
    "y_test_pred = model.predict(X_test_normalized)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Teste - MAE: {test_mae:.5f}\")\n",
    "print(f\"Teste - MSE: {test_mse:.5f}\")\n",
    "print(f\"Teste - RMSE: {test_rmse:.5f}\")\n",
    "print(f\"Teste - R²: {test_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots dos Valores Reais e dos Valores Previstos por Empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o DataFrame com os valores reais e previstos\n",
    "y_test_df = pd.DataFrame(y_test.values, columns=['Real_Return'], index=y_test.index)\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred, columns=['Predicted_Return'], index=y_test.index)\n",
    "df_test = pd.concat([y_test_df, y_test_pred_df], axis=1)\n",
    "df_test['Ticker'] = X_test['Ticker']\n",
    "\n",
    "# Gráficos por empresa\n",
    "tickers = df_test['Ticker'].unique()\n",
    "n_col = 5  \n",
    "n_row = int(np.ceil(len(tickers) / n_col))  \n",
    "\n",
    "print(\"Linha azul --- Valores Reais\")\n",
    "print(\"Linha laranja --- Valores Previstos\")\n",
    "\n",
    "# Criar os subgráficos\n",
    "fig, axes = plt.subplots(n_row, n_col, figsize=(18, 3 * n_row))  \n",
    "axes = axes.flatten()  \n",
    "\n",
    "# Iterar sobre os tickers e plotar os gráficos\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ticker_data = df_test[df_test['Ticker'] == ticker]\n",
    "    ax = axes[i]  \n",
    "    ax.plot(ticker_data.index, ticker_data['Real_Return'], label='Valores Reais', color='blue')\n",
    "    ax.plot(ticker_data.index, ticker_data['Predicted_Return'], label='Previsões', color='orange', linestyle='dashed')\n",
    "    ax.set_title(f'Previsão de Retornos para {ticker}', fontsize=6)  \n",
    "    ax.set_xlabel('Data', fontsize=6) \n",
    "    ax.set_ylabel('Retorno Futuro', fontsize=6) \n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=6)  \n",
    "    ax.tick_params(axis='y', labelsize=6)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5, right=0.85)  \n",
    "plt.tight_layout(pad=3.0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar o csv com os valores reais e previstos\n",
    "df_test.to_csv(\"predicted_vs_real_returns_lgbm.csv\", index=True)\n",
    "print(\"DataFrame salvo como 'predicted_vs_real_returns_lgbm.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valores Reais e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=pd.read_csv(\"predicted_vs_real_returns_adaboost.csv\")\n",
    "ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=pd.read_csv(\"predicted_vs_real_returns_xgboost.csv\")\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb=pd.read_csv(\"predicted_vs_real_returns_lgbm.csv\")\n",
    "lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Monte Carlo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **Monte Carlo** foi desenvolvido com o objetivo de simular várias combinações de ações para encontrar a melhor estratégia de investimento, tendo por base o retono previsto e o retorno real.\n",
    "\n",
    "Primeiro, implementámos a função *monte_carlo_selection* responsável por gerar combinações aleatórias de ações disponíveis em cada dia e por selecionar a melhor, ou seja, a que maximiza o retorno previsto.\n",
    "\n",
    "Definimos também a função *optimize_portfolio*, que aplica a função anterior a vários dias consecutivos e organiza os resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_selection(df_day, max_combinations, explore_rate=0.1):\n",
    "    tickers = df_day['Ticker'].unique()\n",
    "    num_tickers = len(tickers)\n",
    "    best_combination = None\n",
    "    best_predicted_return = -np.inf\n",
    "    best_real_return = -np.inf  # Inicializa o melhor retorno real\n",
    "\n",
    "    for i in range(max_combinations):\n",
    "        if random.random() < explore_rate and best_combination is not None:\n",
    "            # Modificar uma combinação já conhecida\n",
    "            num_changes = random.randint(1, len(best_combination))\n",
    "            random_combination = list(best_combination)\n",
    "            for _ in range(num_changes):\n",
    "                if random.random() < 0.5 and random_combination:\n",
    "                    # Remove um ticker aleatório\n",
    "                    random_combination.pop(random.randint(0, len(random_combination) - 1))\n",
    "                else:\n",
    "                    # Adiciona um novo ticker aleatório\n",
    "                    available_tickers = list(set(tickers) - set(random_combination))\n",
    "                    if available_tickers:  # Verificar se há tickers disponíveis\n",
    "                        new_ticker = random.choice(available_tickers)\n",
    "                        random_combination.append(new_ticker)\n",
    "        else:\n",
    "            # Gerar uma nova combinação\n",
    "            num_selected = random.randint(1, num_tickers)\n",
    "            random_combination = random.sample(list(tickers), num_selected)\n",
    "\n",
    "        # Filtrar o DataFrame para as ações na combinação\n",
    "        df_comb = df_day[df_day['Ticker'].isin(random_combination)]\n",
    "        \n",
    "        # Calcular o retorno total previsto e real\n",
    "        total_predicted_return = df_comb['Predicted_Return'].sum()\n",
    "        total_real_return = df_comb['Real_Return'].sum()\n",
    "        \n",
    "        # Verificar se essa combinação é a melhor até ao momento\n",
    "        if total_predicted_return > best_predicted_return and total_predicted_return > 0:\n",
    "            best_combination = random_combination\n",
    "            best_predicted_return = total_predicted_return\n",
    "            best_real_return = total_real_return\n",
    "\n",
    "    # Verificar se nenhuma combinação válida foi encontrada\n",
    "    if best_combination is None:\n",
    "        best_combination = []\n",
    "        best_predicted_return = 0\n",
    "        best_real_return = 0\n",
    "\n",
    "    return {\n",
    "        \"best_combination\": best_combination,\n",
    "        \"com_predicted_return\": best_predicted_return,\n",
    "        \"com_real_return\": best_real_return  \n",
    "    }\n",
    "\n",
    "# Aplicar a otimização por dia\n",
    "def optimize_portfolio(df_test, max_combinations=1000):\n",
    "    results = []\n",
    "    for date, df_day in df_test.groupby('Date'):  \n",
    "        \n",
    "        result = monte_carlo_selection(df_day, max_combinations=max_combinations)\n",
    "        result['Date'] = date\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ada = optimize_portfolio(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb = optimize_portfolio(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lgb = optimize_portfolio(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo das métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Métricas financeiras**: Avaliam os retornos médios e acumulados, tanto previstos como reais, permitindo analisar o crescimento do portefólio ao longo do tempo.\n",
    "\n",
    "- **Métricas de performance**: Medem a qualidade das previsões e a eficácia do portólio em alcançar retornos positivos. Estas métricas envolvem a taxa de acerto, isto é, a proporção de dias com retornos reais positivos (*Hit Rate*), o erro absoluto médio (MAE) e o coeficiente de determinação (R²).\n",
    "\n",
    "- **Métricas de risco**: Avaliam a relação entre o retorno e a volatilidade para determinar a eficiência do portefólio em gerar retornos ajustados ao risco (*Sharpe Ratio* real e previsto).\n",
    "\n",
    "- **Métricas diárias**: Estas métricas, retorno médio diário, volatilidade diária e *Sharpe Ration* , avaliam a performance do modelo diariamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(results_df):\n",
    "    # Filtrar apenas dias com combinações selecionadas\n",
    "    selected_days = results_df[results_df['best_combination'].apply(len) > 0].copy()  \n",
    "    \n",
    "    # Retornos previstos e reais\n",
    "    predicted_returns = selected_days['com_predicted_return']\n",
    "    real_returns = selected_days['com_real_return']\n",
    "    \n",
    "    # Cálculo de métricas principais\n",
    "    metrics = {}\n",
    "    metrics['Average_Predicted_Return'] = predicted_returns.mean()\n",
    "    metrics['Average_Real_Return'] = real_returns.mean()\n",
    "    metrics['Hit_Rate'] = (real_returns > 0).mean()\n",
    "    metrics['MAE'] = np.mean(np.abs(predicted_returns - real_returns))\n",
    "    metrics['R2'] = r2(real_returns, predicted_returns) if len(real_returns) > 1 else np.nan\n",
    "    metrics['Sharpe_Ratio_Real'] = (\n",
    "        real_returns.mean() / real_returns.std() if real_returns.std() > 0 else np.nan\n",
    "    )\n",
    "    metrics['Sharpe_Ratio_Predicted'] = (\n",
    "        predicted_returns.mean() / predicted_returns.std() if predicted_returns.std() > 0 else np.nan\n",
    "    )\n",
    "    \n",
    "    # Cálculo de retornos acumulados \n",
    "    selected_days.loc[:, 'Cumulative_Real_Return'] = (1 + real_returns).cumprod()\n",
    "    selected_days.loc[:, 'Cumulative_Predicted_Return'] = (1 + predicted_returns).cumprod()\n",
    "    \n",
    "    metrics['Cumulative_Real_Return_Final'] = selected_days['Cumulative_Real_Return'].iloc[-1]\n",
    "    metrics['Cumulative_Predicted_Return_Final'] = selected_days['Cumulative_Predicted_Return'].iloc[-1]\n",
    "    \n",
    "    # Cálculo de retornos diários com base nos acumulados \n",
    "    selected_days.loc[:, 'daily_real_return'] = selected_days['Cumulative_Real_Return'].pct_change()\n",
    "    selected_days.loc[:, 'daily_predicted_return'] = selected_days['Cumulative_Predicted_Return'].pct_change()\n",
    "    \n",
    "    metrics['Daily_Mean_Real_Return'] = selected_days['daily_real_return'].mean()\n",
    "    metrics['Daily_Mean_Predicted_Return'] = selected_days['daily_predicted_return'].mean()\n",
    "    metrics['Daily_Std_Real_Return'] = selected_days['daily_real_return'].std()\n",
    "    metrics['Daily_Std_Predicted_Return'] = selected_days['daily_predicted_return'].std()\n",
    "    \n",
    "    # Sharpe Ratios diários\n",
    "    metrics['Sharpe_Ratio_Daily_Real'] = (\n",
    "        metrics['Daily_Mean_Real_Return'] / metrics['Daily_Std_Real_Return']\n",
    "        if metrics['Daily_Std_Real_Return'] > 0 else np.nan\n",
    "    )\n",
    "    metrics['Sharpe_Ratio_Daily_Predicted'] = (\n",
    "        metrics['Daily_Mean_Predicted_Return'] / metrics['Daily_Std_Predicted_Return']\n",
    "        if metrics['Daily_Std_Predicted_Return'] > 0 else np.nan\n",
    "    )\n",
    "    \n",
    "    # Formatar resultados para apresentação\n",
    "    formatted_results = f\"\"\"\n",
    "    ### Resumo de Desempenho do Modelo Preditivo ###\n",
    "    \n",
    "    **Métricas de Retorno:**\n",
    "    - Retorno Médio Previsto: {metrics['Average_Predicted_Return']:.4f}\n",
    "    - Retorno Médio Real: {metrics['Average_Real_Return']:.4f}\n",
    "    - Retorno Acumulado Final (Real): {metrics['Cumulative_Real_Return_Final']:.4f}\n",
    "    - Retorno Acumulado Final (Previsto): {metrics['Cumulative_Predicted_Return_Final']:.4f}\n",
    "    \n",
    "    **Métricas de Performance:**\n",
    "    - Taxa de Acerto (Hit Rate): {metrics['Hit_Rate']:.2%}\n",
    "    - Erro Absoluto Médio (MAE): {metrics['MAE']:.4f}\n",
    "    - Coeficiente de Determinação (R²): {metrics['R2']:.4f}\n",
    "    \n",
    "    **Métricas de Risco:**\n",
    "    - Sharpe Ratio (Real): {metrics['Sharpe_Ratio_Real']:.4f}\n",
    "    - Sharpe Ratio (Previsto): {metrics['Sharpe_Ratio_Predicted']:.4f}\n",
    "    \n",
    "    **Métricas Diárias:**\n",
    "    - Retorno Médio Diário (Real): {metrics['Daily_Mean_Real_Return']:.4f}\n",
    "    - Retorno Médio Diário (Previsto): {metrics['Daily_Mean_Predicted_Return']:.4f}\n",
    "    - Volatilidade Diária (Real): {metrics['Daily_Std_Real_Return']:.4f}\n",
    "    - Volatilidade Diária (Previsto): {metrics['Daily_Std_Predicted_Return']:.4f}\n",
    "    - Sharpe Ratio Diário (Real): {metrics['Sharpe_Ratio_Daily_Real']:.4f}\n",
    "    - Sharpe Ratio Diário (Previsto): {metrics['Sharpe_Ratio_Daily_Predicted']:.4f}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Desempenho do AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(results_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pela análise das métricas, percebemos que o AdaBoost demostrou uma elevada capacidade para prever, com um R² e uma *Hit Rate* elevados.\n",
    "\n",
    "No entanto, o modelo substima os retornos reais, tal como podemos obversar na diferença entre os retornos médios e os acumulados.\n",
    "\n",
    "Apesar disso, este revela uma boa gestão de risco, apresentando um *Sharp Ratio* real positivo, embora inferior ao previsto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Desempenho do XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(results_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com as métricas, verificamos que o XGBoost apresenta um bom desempenho, com um R² elevado, mostrando que o modelo é capaz de explicar a variação dos retornos futuros. \n",
    "\n",
    "Contudo, este apresenta um erro absoluto médio relativamente alto e a *Hit Rate* de 52.38% indicam uma certa dificuldade em prever os retornos com precisão exata. Ainda assim, o *Sharp Ratio* previsto supera o real, o que sugere que o modelo favorece escolhas consistentes e ajustadas ao risco.\n",
    "\n",
    "No entanto, os retornos médios previstos são consideravelmente inferiores aos reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Desempenho do LightBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(results_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas métricas mostram um desempenho sólido, por parte do LightGBM, com um R² bastante elevado, refletindo a alta capacidade de explicação da variabilidade dos retornos. \n",
    "\n",
    "A *Hit Rate* é bastante positiva, contudo o erro absoluto médio sugere que há erros consideráveis nas previsões. Já o *Sharp Ratio* é superior ao real, destacando maior consistência ajustada ao risco nas previsões. \n",
    "\n",
    "No entanto, os retornos médios previstos são inferiores aos reais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P2_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
